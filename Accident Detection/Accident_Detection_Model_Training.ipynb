{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Accident Detection Model Training\n",
                "\n",
                "This notebook trains a deep learning model to detect accidents from traffic camera images.\n",
                "\n",
                "## Dataset Structure\n",
                "- **Train**: Images for training the model\n",
                "- **Validation**: Images for hyperparameter tuning\n",
                "- **Test**: Images for final evaluation\n",
                "\n",
                "Each split contains two classes:\n",
                "- `Accident`: Images showing traffic accidents\n",
                "- `Non Accident`: Normal traffic images"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Deep Learning Libraries\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0, ResNet50\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "\n",
                "# Scikit-learn for metrics\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"TensorFlow Version: {tf.__version__}\")\n",
                "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configure Paths and Hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data paths\n",
                "DATA_DIR = Path('data')\n",
                "TRAIN_DIR = DATA_DIR / 'train'\n",
                "VAL_DIR = DATA_DIR / 'val'\n",
                "TEST_DIR = DATA_DIR / 'test'\n",
                "\n",
                "# Model hyperparameters\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 50\n",
                "LEARNING_RATE = 0.001\n",
                "CLASS_NAMES = ['Accident', 'Non Accident']\n",
                "\n",
                "# Create models directory\n",
                "MODEL_DIR = Path('models')\n",
                "MODEL_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(f\"Train Directory: {TRAIN_DIR}\")\n",
                "print(f\"Validation Directory: {VAL_DIR}\")\n",
                "print(f\"Test Directory: {TEST_DIR}\")\n",
                "print(f\"Image Size: {IMG_SIZE}\")\n",
                "print(f\"Batch Size: {BATCH_SIZE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Explore Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count images in each split\n",
                "def count_images(directory):\n",
                "    counts = {}\n",
                "    for class_name in CLASS_NAMES:\n",
                "        class_path = directory / class_name\n",
                "        if class_path.exists():\n",
                "            counts[class_name] = len(list(class_path.glob('*.jpg'))) + len(list(class_path.glob('*.png')))\n",
                "        else:\n",
                "            counts[class_name] = 0\n",
                "    return counts\n",
                "\n",
                "train_counts = count_images(TRAIN_DIR)\n",
                "val_counts = count_images(VAL_DIR)\n",
                "test_counts = count_images(TEST_DIR)\n",
                "\n",
                "print(\"Dataset Distribution:\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\nTrain Set:\")\n",
                "for class_name, count in train_counts.items():\n",
                "    print(f\"  {class_name}: {count} images\")\n",
                "print(f\"  Total: {sum(train_counts.values())} images\")\n",
                "\n",
                "print(f\"\\nValidation Set:\")\n",
                "for class_name, count in val_counts.items():\n",
                "    print(f\"  {class_name}: {count} images\")\n",
                "print(f\"  Total: {sum(val_counts.values())} images\")\n",
                "\n",
                "print(f\"\\nTest Set:\")\n",
                "for class_name, count in test_counts.items():\n",
                "    print(f\"  {class_name}: {count} images\")\n",
                "print(f\"  Total: {sum(test_counts.values())} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize dataset distribution\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "datasets = [('Train', train_counts), ('Validation', val_counts), ('Test', test_counts)]\n",
                "\n",
                "for idx, (name, counts) in enumerate(datasets):\n",
                "    axes[idx].bar(counts.keys(), counts.values(), color=['#e74c3c', '#3498db'])\n",
                "    axes[idx].set_title(f'{name} Set Distribution', fontsize=12, fontweight='bold')\n",
                "    axes[idx].set_ylabel('Number of Images')\n",
                "    axes[idx].set_xlabel('Class')\n",
                "    axes[idx].grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    # Add value labels on bars\n",
                "    for i, (class_name, count) in enumerate(counts.items()):\n",
                "        axes[idx].text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display sample images from each class\n",
                "def display_samples(directory, num_samples=5):\n",
                "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
                "    \n",
                "    for idx, class_name in enumerate(CLASS_NAMES):\n",
                "        class_path = directory / class_name\n",
                "        image_files = list(class_path.glob('*.jpg'))[:num_samples]\n",
                "        \n",
                "        for i, img_path in enumerate(image_files):\n",
                "            img = plt.imread(img_path)\n",
                "            axes[idx, i].imshow(img)\n",
                "            axes[idx, i].axis('off')\n",
                "            if i == 0:\n",
                "                axes[idx, i].set_title(f'{class_name}', fontsize=12, fontweight='bold')\n",
                "    \n",
                "    plt.suptitle('Sample Images from Training Set', fontsize=14, fontweight='bold', y=1.02)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "display_samples(TRAIN_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Augmentation and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data augmentation for training set\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=20,\n",
                "    width_shift_range=0.2,\n",
                "    height_shift_range=0.2,\n",
                "    shear_range=0.2,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True,\n",
                "    brightness_range=[0.8, 1.2],\n",
                "    fill_mode='nearest'\n",
                ")\n",
                "\n",
                "# Only rescaling for validation and test sets\n",
                "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "# Create data generators\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    target_size=IMG_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    shuffle=True,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "val_generator = val_test_datagen.flow_from_directory(\n",
                "    VAL_DIR,\n",
                "    target_size=IMG_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "test_generator = val_test_datagen.flow_from_directory(\n",
                "    TEST_DIR,\n",
                "    target_size=IMG_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "print(f\"\\nClass Indices: {train_generator.class_indices}\")\n",
                "print(f\"Total Training Batches: {len(train_generator)}\")\n",
                "print(f\"Total Validation Batches: {len(val_generator)}\")\n",
                "print(f\"Total Test Batches: {len(test_generator)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build Model Architecture\n",
                "\n",
                "We'll use transfer learning with MobileNetV2 as the base model for efficient and accurate accident detection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_model(base_model_name='MobileNetV2', trainable_layers=20):\n",
                "    \"\"\"\n",
                "    Create a transfer learning model for accident detection.\n",
                "    \n",
                "    Args:\n",
                "        base_model_name: Name of the base model ('MobileNetV2', 'EfficientNetB0', 'ResNet50')\n",
                "        trainable_layers: Number of layers to unfreeze for fine-tuning\n",
                "    \"\"\"\n",
                "    # Load pre-trained base model\n",
                "    if base_model_name == 'MobileNetV2':\n",
                "        base_model = MobileNetV2(input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
                "    elif base_model_name == 'EfficientNetB0':\n",
                "        base_model = EfficientNetB0(input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
                "    elif base_model_name == 'ResNet50':\n",
                "        base_model = ResNet50(input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
                "    else:\n",
                "        raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
                "    \n",
                "    # Freeze base model layers initially\n",
                "    base_model.trainable = False\n",
                "    \n",
                "    # Build the model\n",
                "    model = models.Sequential([\n",
                "        base_model,\n",
                "        layers.GlobalAveragePooling2D(),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Dropout(0.5),\n",
                "        layers.Dense(256, activation='relu'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Dropout(0.3),\n",
                "        layers.Dense(128, activation='relu'),\n",
                "        layers.Dropout(0.2),\n",
                "        layers.Dense(1, activation='sigmoid')\n",
                "    ])\n",
                "    \n",
                "    return model, base_model\n",
                "\n",
                "# Create the model\n",
                "model, base_model = create_model('MobileNetV2')\n",
                "\n",
                "# Compile the model\n",
                "model.compile(\n",
                "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
                ")\n",
                "\n",
                "# Display model summary\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Setup Training Callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define callbacks\n",
                "callbacks = [\n",
                "    # Early stopping to prevent overfitting\n",
                "    EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=10,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Reduce learning rate when validation loss plateaus\n",
                "    ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=5,\n",
                "        min_lr=1e-7,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Save best model\n",
                "    ModelCheckpoint(\n",
                "        filepath=str(MODEL_DIR / 'best_accident_model.h5'),\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"Callbacks configured successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Train the Model (Initial Training)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "print(\"Starting initial training with frozen base model...\\n\")\n",
                "\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=val_generator,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\nInitial training completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Fine-Tuning (Unfreeze Some Layers)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Unfreeze the last layers of the base model for fine-tuning\n",
                "base_model.trainable = True\n",
                "\n",
                "# Freeze all layers except the last 20\n",
                "for layer in base_model.layers[:-20]:\n",
                "    layer.trainable = False\n",
                "\n",
                "# Recompile with lower learning rate\n",
                "model.compile(\n",
                "    optimizer=Adam(learning_rate=LEARNING_RATE/10),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
                ")\n",
                "\n",
                "print(f\"Fine-tuning with {sum([1 for layer in base_model.layers if layer.trainable])} trainable layers\")\n",
                "\n",
                "# Continue training with fine-tuning\n",
                "history_fine = model.fit(\n",
                "    train_generator,\n",
                "    epochs=20,\n",
                "    validation_data=val_generator,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\nFine-tuning completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Visualize Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_training_history(history, history_fine=None):\n",
                "    \"\"\"\n",
                "    Plot training and validation metrics over epochs.\n",
                "    \"\"\"\n",
                "    # Combine histories if fine-tuning was performed\n",
                "    if history_fine:\n",
                "        for key in history.history.keys():\n",
                "            history.history[key].extend(history_fine.history[key])\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
                "    \n",
                "    # Accuracy\n",
                "    axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
                "    axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
                "    axes[0, 0].set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
                "    axes[0, 0].set_xlabel('Epoch')\n",
                "    axes[0, 0].set_ylabel('Accuracy')\n",
                "    axes[0, 0].legend()\n",
                "    axes[0, 0].grid(alpha=0.3)\n",
                "    \n",
                "    # Loss\n",
                "    axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
                "    axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
                "    axes[0, 1].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
                "    axes[0, 1].set_xlabel('Epoch')\n",
                "    axes[0, 1].set_ylabel('Loss')\n",
                "    axes[0, 1].legend()\n",
                "    axes[0, 1].grid(alpha=0.3)\n",
                "    \n",
                "    # Precision\n",
                "    axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
                "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
                "    axes[1, 0].set_title('Model Precision', fontsize=12, fontweight='bold')\n",
                "    axes[1, 0].set_xlabel('Epoch')\n",
                "    axes[1, 0].set_ylabel('Precision')\n",
                "    axes[1, 0].legend()\n",
                "    axes[1, 0].grid(alpha=0.3)\n",
                "    \n",
                "    # Recall\n",
                "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
                "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
                "    axes[1, 1].set_title('Model Recall', fontsize=12, fontweight='bold')\n",
                "    axes[1, 1].set_xlabel('Epoch')\n",
                "    axes[1, 1].set_ylabel('Recall')\n",
                "    axes[1, 1].legend()\n",
                "    axes[1, 1].grid(alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "plot_training_history(history, history_fine)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "print(\"Evaluating model on test set...\\n\")\n",
                "\n",
                "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator, verbose=1)\n",
                "\n",
                "# Calculate F1 Score\n",
                "test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"TEST SET RESULTS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Test Loss: {test_loss:.4f}\")\n",
                "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
                "print(f\"Test Precision: {test_precision:.4f}\")\n",
                "print(f\"Test Recall: {test_recall:.4f}\")\n",
                "print(f\"Test F1-Score: {test_f1:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Generate Predictions and Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get predictions\n",
                "test_generator.reset()\n",
                "y_pred_probs = model.predict(test_generator, verbose=1)\n",
                "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
                "y_true = test_generator.classes\n",
                "\n",
                "print(f\"\\nPredictions shape: {y_pred.shape}\")\n",
                "print(f\"True labels shape: {y_true.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
                "            cbar_kws={'label': 'Count'})\n",
                "plt.title('Confusion Matrix - Accident Detection', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('True Label', fontsize=12)\n",
                "plt.xlabel('Predicted Label', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nConfusion Matrix:\")\n",
                "print(cm)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Classification Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detailed classification report\n",
                "print(\"\\nClassification Report:\")\n",
                "print(\"=\"*60)\n",
                "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. ROC Curve and AUC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate ROC curve and AUC\n",
                "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
                "roc_auc = auc(fpr, tpr)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate', fontsize=12)\n",
                "plt.ylabel('True Positive Rate', fontsize=12)\n",
                "plt.title('ROC Curve - Accident Detection Model', fontsize=14, fontweight='bold')\n",
                "plt.legend(loc='lower right', fontsize=11)\n",
                "plt.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nArea Under ROC Curve (AUC): {roc_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. Visualize Predictions on Test Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize predictions on random test images\n",
                "def visualize_predictions(generator, model, num_images=12):\n",
                "    \"\"\"\n",
                "    Display predictions on random test images.\n",
                "    \"\"\"\n",
                "    generator.reset()\n",
                "    x_batch, y_batch = next(generator)\n",
                "    predictions = model.predict(x_batch[:num_images])\n",
                "    \n",
                "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
                "    axes = axes.flatten()\n",
                "    \n",
                "    for i in range(num_images):\n",
                "        axes[i].imshow(x_batch[i])\n",
                "        \n",
                "        true_label = CLASS_NAMES[int(y_batch[i])]\n",
                "        pred_label = CLASS_NAMES[int(predictions[i] > 0.5)]\n",
                "        confidence = predictions[i][0] if predictions[i] > 0.5 else 1 - predictions[i][0]\n",
                "        \n",
                "        color = 'green' if true_label == pred_label else 'red'\n",
                "        \n",
                "        axes[i].set_title(\n",
                "            f'True: {true_label}\\nPred: {pred_label} ({confidence:.2%})',\n",
                "            color=color,\n",
                "            fontsize=10,\n",
                "            fontweight='bold'\n",
                "        )\n",
                "        axes[i].axis('off')\n",
                "    \n",
                "    plt.suptitle('Model Predictions on Test Images', fontsize=14, fontweight='bold', y=0.98)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "visualize_predictions(test_generator, model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 16. Save the Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the complete model\n",
                "model_path = MODEL_DIR / 'accident_detection_model_final.h5'\n",
                "model.save(model_path)\n",
                "print(f\"Model saved to: {model_path}\")\n",
                "\n",
                "# Save model in TensorFlow SavedModel format (for deployment)\n",
                "saved_model_path = MODEL_DIR / 'accident_detection_saved_model'\n",
                "model.save(saved_model_path, save_format='tf')\n",
                "print(f\"SavedModel format saved to: {saved_model_path}\")\n",
                "\n",
                "# Save model weights only\n",
                "weights_path = MODEL_DIR / 'accident_detection_weights.h5'\n",
                "model.save_weights(weights_path)\n",
                "print(f\"Model weights saved to: {weights_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 17. Model Summary and Performance Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a summary DataFrame\n",
                "summary_data = {\n",
                "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC'],\n",
                "    'Score': [test_accuracy, test_precision, test_recall, test_f1, roc_auc]\n",
                "}\n",
                "\n",
                "summary_df = pd.DataFrame(summary_data)\n",
                "summary_df['Score (%)'] = summary_df['Score'] * 100\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(summary_df.to_string(index=False))\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Visualize metrics\n",
                "plt.figure(figsize=(10, 6))\n",
                "bars = plt.bar(summary_df['Metric'], summary_df['Score'], \n",
                "               color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6'])\n",
                "plt.ylim([0, 1.1])\n",
                "plt.ylabel('Score', fontsize=12)\n",
                "plt.title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Add value labels on bars\n",
                "for bar in bars:\n",
                "    height = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
                "             f'{height:.4f}',\n",
                "             ha='center', va='bottom', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 18. Load and Test Saved Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the saved model to verify it works\n",
                "loaded_model = keras.models.load_model(model_path)\n",
                "print(\"Model loaded successfully!\\n\")\n",
                "\n",
                "# Test the loaded model\n",
                "test_generator.reset()\n",
                "loaded_test_loss, loaded_test_accuracy, loaded_test_precision, loaded_test_recall = loaded_model.evaluate(\n",
                "    test_generator, verbose=0\n",
                ")\n",
                "\n",
                "print(\"Loaded Model Test Results:\")\n",
                "print(f\"  Accuracy: {loaded_test_accuracy:.4f}\")\n",
                "print(f\"  Precision: {loaded_test_precision:.4f}\")\n",
                "print(f\"  Recall: {loaded_test_recall:.4f}\")\n",
                "print(\"\\nâœ“ Model saved and loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 19. Inference Function for New Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_accident(image_path, model, threshold=0.5):\n",
                "    \"\"\"\n",
                "    Predict whether an image contains an accident.\n",
                "    \n",
                "    Args:\n",
                "        image_path: Path to the image file\n",
                "        model: Trained Keras model\n",
                "        threshold: Classification threshold (default: 0.5)\n",
                "    \n",
                "    Returns:\n",
                "        prediction: Class label ('Accident' or 'Non Accident')\n",
                "        confidence: Prediction confidence score\n",
                "    \"\"\"\n",
                "    # Load and preprocess image\n",
                "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
                "    img_array = keras.preprocessing.image.img_to_array(img)\n",
                "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
                "    \n",
                "    # Make prediction\n",
                "    prediction_prob = model.predict(img_array, verbose=0)[0][0]\n",
                "    \n",
                "    if prediction_prob > threshold:\n",
                "        prediction = 'Non Accident'\n",
                "        confidence = prediction_prob\n",
                "    else:\n",
                "        prediction = 'Accident'\n",
                "        confidence = 1 - prediction_prob\n",
                "    \n",
                "    return prediction, confidence\n",
                "\n",
                "# Example usage\n",
                "print(\"Inference function created successfully!\")\n",
                "print(\"\\nUsage example:\")\n",
                "print(\"  prediction, confidence = predict_accident('path/to/image.jpg', model)\")\n",
                "print(\"  print(f'Prediction: {prediction} (Confidence: {confidence:.2%})')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 20. Test Inference on Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test inference on a few sample images\n",
                "sample_images = []\n",
                "\n",
                "# Get sample images from test set\n",
                "for class_name in CLASS_NAMES:\n",
                "    class_path = TEST_DIR / class_name\n",
                "    images = list(class_path.glob('*.jpg'))[:2]\n",
                "    sample_images.extend(images)\n",
                "\n",
                "# Display predictions\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, img_path in enumerate(sample_images[:4]):\n",
                "    # Make prediction\n",
                "    prediction, confidence = predict_accident(str(img_path), model)\n",
                "    \n",
                "    # Display image\n",
                "    img = plt.imread(img_path)\n",
                "    axes[i].imshow(img)\n",
                "    \n",
                "    # Get true label from path\n",
                "    true_label = img_path.parent.name\n",
                "    \n",
                "    # Set title color based on correctness\n",
                "    color = 'green' if prediction == true_label else 'red'\n",
                "    \n",
                "    axes[i].set_title(\n",
                "        f'True: {true_label}\\nPredicted: {prediction}\\nConfidence: {confidence:.2%}',\n",
                "        color=color,\n",
                "        fontsize=11,\n",
                "        fontweight='bold'\n",
                "    )\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle('Inference Test on Sample Images', fontsize=14, fontweight='bold', y=0.98)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 21. Model Export Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(\"\\nðŸ“Š Final Performance:\")\n",
                "print(f\"   â€¢ Test Accuracy: {test_accuracy*100:.2f}%\")\n",
                "print(f\"   â€¢ Test Precision: {test_precision:.4f}\")\n",
                "print(f\"   â€¢ Test Recall: {test_recall:.4f}\")\n",
                "print(f\"   â€¢ Test F1-Score: {test_f1:.4f}\")\n",
                "print(f\"   â€¢ AUC-ROC: {roc_auc:.4f}\")\n",
                "\n",
                "print(\"\\nðŸ’¾ Saved Models:\")\n",
                "print(f\"   â€¢ Full Model (H5): {model_path}\")\n",
                "print(f\"   â€¢ SavedModel Format: {saved_model_path}\")\n",
                "print(f\"   â€¢ Model Weights: {weights_path}\")\n",
                "print(f\"   â€¢ Best Model (Checkpoint): {MODEL_DIR / 'best_accident_model.h5'}\")\n",
                "\n",
                "print(\"\\nðŸŽ¯ Model Details:\")\n",
                "print(f\"   â€¢ Architecture: Transfer Learning with MobileNetV2\")\n",
                "print(f\"   â€¢ Input Size: {IMG_SIZE}\")\n",
                "print(f\"   â€¢ Classes: {CLASS_NAMES}\")\n",
                "print(f\"   â€¢ Total Parameters: {model.count_params():,}\")\n",
                "\n",
                "print(\"\\nâœ… Ready for deployment!\")\n",
                "print(\"=\"*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}